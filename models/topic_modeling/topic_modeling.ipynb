{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try use topic modeling to calculate the semantic similarities between the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "# improve the model with lemmatization \n",
    "# use a different vectorizer. \n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "count_vectorizer = text.CountVectorizer(tokenizer=LemmaTokenizer(),\n",
    "                                strip_accents = 'unicode', # works \n",
    "                                stop_words = 'english', # works\n",
    "                                lowercase = True, # works\n",
    "                                max_df = 0.5, # works\n",
    "                                min_df = 10) # works\n",
    "\n",
    "\n",
    "tfidf_vectorizer = text.TfidfVectorizer(tokenizer=LemmaTokenizer(),\n",
    "                                strip_accents = 'unicode', # works \n",
    "                                stop_words = 'english', # works\n",
    "                                lowercase = True, # works\n",
    "                                max_df = 0.5, # works\n",
    "                                min_df = 10) # works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_phys = pd.read_csv(\"../../nlp_clean/wiki_phys_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wikipedia:FAQ/Categorization</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Wikipedia:FAQ/Ca...</td>\n",
       "      <td>Concepts in physics</td>\n",
       "      <td>help faq categorization faq frequently asked q...</td>\n",
       "      <td>3359</td>\n",
       "      <td>['Help:Contents', 'Help:Contents', 'Wikipedia:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Category:Concepts in physics</td>\n",
       "      <td>https://en.wikipedia.org/w/index.php?title=Cat...</td>\n",
       "      <td>Concepts in physics</td>\n",
       "      <td>category comprises topic fundamental descripti...</td>\n",
       "      <td>94</td>\n",
       "      <td>['Wave', 'Momentum', 'Wikipedia:FAQ/Categoriza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4D vector</td>\n",
       "      <td>https://en.wikipedia.org/wiki/4D_vector</td>\n",
       "      <td>Concepts in physics</td>\n",
       "      <td>computer science vector vector data type us in...</td>\n",
       "      <td>441</td>\n",
       "      <td>['Computer science', 'Vector (mathematics)', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Active and passive transformation</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Active_and_passi...</td>\n",
       "      <td>Concepts in physics</td>\n",
       "      <td>physic engineering spatial transformation eucl...</td>\n",
       "      <td>1121</td>\n",
       "      <td>['Physics', 'Engineering', 'Transformation (ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ansatz</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Ansatz</td>\n",
       "      <td>Concepts in physics</td>\n",
       "      <td>physic mathematics ansatz german ˈʔanzats mean...</td>\n",
       "      <td>276</td>\n",
       "      <td>['Physics', 'Mathematics', 'Help:IPA/English',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name  \\\n",
       "0       Wikipedia:FAQ/Categorization   \n",
       "1       Category:Concepts in physics   \n",
       "2                          4D vector   \n",
       "3  Active and passive transformation   \n",
       "4                             Ansatz   \n",
       "\n",
       "                                                Link          Subcategory  \\\n",
       "0  https://en.wikipedia.org/wiki/Wikipedia:FAQ/Ca...  Concepts in physics   \n",
       "1  https://en.wikipedia.org/w/index.php?title=Cat...  Concepts in physics   \n",
       "2            https://en.wikipedia.org/wiki/4D_vector  Concepts in physics   \n",
       "3  https://en.wikipedia.org/wiki/Active_and_passi...  Concepts in physics   \n",
       "4               https://en.wikipedia.org/wiki/Ansatz  Concepts in physics   \n",
       "\n",
       "                                                Text  Length  \\\n",
       "0  help faq categorization faq frequently asked q...    3359   \n",
       "1  category comprises topic fundamental descripti...      94   \n",
       "2  computer science vector vector data type us in...     441   \n",
       "3  physic engineering spatial transformation eucl...    1121   \n",
       "4  physic mathematics ansatz german ˈʔanzats mean...     276   \n",
       "\n",
       "                                           Reference  \n",
       "0  ['Help:Contents', 'Help:Contents', 'Wikipedia:...  \n",
       "1  ['Wave', 'Momentum', 'Wikipedia:FAQ/Categoriza...  \n",
       "2  ['Computer science', 'Vector (mathematics)', '...  \n",
       "3  ['Physics', 'Engineering', 'Transformation (ma...  \n",
       "4  ['Physics', 'Mathematics', 'Help:IPA/English',...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_phys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiki_phys['Subcategory'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count_vectorized=count_vectorizer.fit_transform(wiki_phys['Text'].values.astype('U'))\n",
    "lda_model_count=LDA(n_components=26\n",
    "              ,max_iter=100,learning_method='batch', n_jobs=3).fit(data_count_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf_vectorized=tfidf_vectorizer.fit_transform(wiki_phys['Text'].values.astype('U'))\n",
    "lda_model_tfidf=LDA(n_components=26\n",
    "              ,max_iter=100,learning_method='batch', n_jobs=3).fit(data_tfidf_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_topics(lda_model_count, count_vectorizer)\n",
    "\n",
    "#print_topics(lda_model_tfidf, count_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the grouped key words indeed made sense. But how to measure the model's performance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the average precision metric\n",
    "\n",
    "The averaged precision metric is defined as the averaged precision for top 1, top2, top3 ...top10 of the recommended articles to be in the same subcategory as the one you are reading. \n",
    "\n",
    "It is not a perfect metric since you might want diversity in the category you read and relevant articles are not always in the same category. But it is a good metric to use for the first iteration of the recommendation engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
    "\n",
    "def top_n_index_sorted(array, top_n):\n",
    "    # get the index of top 10 values in the array\n",
    "    index = np.argpartition(array,-top_n)[-top_n:]\n",
    "    \n",
    "    # return the index of the sorted top_n values \n",
    "    return index[np.argsort(array[index])]\n",
    "\n",
    "def top10_recommend_index(index,model,data,top_n):\n",
    "    # transform the data using the model\n",
    "    lda_vectors=model.transform(data)\n",
    "    # calculate the cos similarity from the lda vectors \n",
    "    similarity=cos_sim(lda_vectors)\n",
    "    \n",
    "    top_n_index=top_n_index_sorted(similarity[index,],top_n)\n",
    "    \n",
    "    # get the decreasing similarity index\n",
    "    return top_n_index[::-1]    \n",
    "# example \n",
    "# top10_recommend_index(2,lda_model_2,data_count_vectorized,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_averaged_precision(top_n_index,data):\n",
    "    \n",
    "    # get the subcategory data\n",
    "    recommended_subcategory = wiki_phys[\"Subcategory\"].iloc[top_n_index]\n",
    "    recommended_subcategory=recommended_subcategory.values\n",
    "    # set the ground truth \n",
    "    ground_truth = recommended_subcategory[0]\n",
    "    # get the recommended subcategory\n",
    "    recommended_subcategory = recommended_subcategory[1:]\n",
    "    \n",
    "    # calculate the precision to be in the same category. \n",
    "    percentage_list = list()\n",
    "    for index,item in enumerate(recommended_subcategory):\n",
    "        percentage = sum(ground_truth ==recommended_subcategory[:(index+1)] )/len(recommended_subcategory[:(index+1)])\n",
    "        percentage_list.append(percentage)\n",
    "    # return the mean of the percentage_list\n",
    "    return sum(percentage_list)/len(percentage_list)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37971781305114632"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_averaged_precision(top10_recommend_index(10,lda_model_count,data_count_vectorized,10), wiki_phys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_list_count = list()\n",
    "\n",
    "for i in range(wiki_phys.shape[0]):\n",
    "    top10_averaged=top10_averaged_precision(top10_recommend_index(i,lda_model_count,data_count_vectorized,10), wiki_phys)\n",
    "    \n",
    "    precision_list_count.append(top10_averaged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_list_tfidf = list()\n",
    "\n",
    "for i in range(wiki_phys.shape[0]):\n",
    "    top10_averaged=top10_averaged_precision(top10_recommend_index(i,lda_model_tfidf,data_tfidf_vectorized,10), wiki_phys)\n",
    "    \n",
    "    precision_list_tfidf.append(top10_averaged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
